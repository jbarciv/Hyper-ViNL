{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "585ac195-2b69-4dff-8508-5a08f7b65b6e",
   "metadata": {},
   "source": [
    "## For a folder where to find the train.log files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd3b8a8-0dd7-4018-b5e6-9f888b9ce719",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "# LaTeX style setup\n",
    "pgf_with_latex = {\n",
    "    'pgf.texsystem': 'pdflatex',\n",
    "    'text.usetex': True,\n",
    "    'font.size': 10,\n",
    "    'font.family': 'serif',\n",
    "    'font.serif': [],\n",
    "    'font.sans-serif': [],\n",
    "    'font.monospace': [],\n",
    "    'text.latex.preamble': r'\\usepackage[utf8]{inputenc}\\usepackage[T1]{fontenc}\\usepackage[detect-all]{siunitx}\\usepackage{amsmath}\\usepackage{bm}\\usepackage{color}'\n",
    "}\n",
    "\n",
    "mpl.rcParams.update(pgf_with_latex)\n",
    "plt.rcParams[\"axes.axisbelow\"] = True  # Ensure that the grid is drawn behind everything else\n",
    "\n",
    "def parse_log_file(file_path):\n",
    "    iterations = []\n",
    "    rewards = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            iteration_match = re.search(r'Learning iteration (\\d+)/', line)\n",
    "            if iteration_match:\n",
    "                iteration = int(iteration_match.group(1))\n",
    "            \n",
    "            reward_match = re.search(r'Mean reward: ([\\d\\.-]+)', line)\n",
    "            if reward_match:\n",
    "                reward = float(reward_match.group(1))\n",
    "                iterations.append(iteration)\n",
    "                rewards.append(reward)\n",
    "    return iterations, rewards\n",
    "\n",
    "def process_logs_in_directory(directory_path):\n",
    "    # Define the log files of interest\n",
    "    log_files = ['obs_train.log', 'rough_train.log']\n",
    "    \n",
    "    # Process each log file\n",
    "    for log_file_name in log_files:\n",
    "        log_file_path = os.path.join(directory_path, log_file_name)\n",
    "        if not os.path.isfile(log_file_path):\n",
    "            print(f\"Log file {log_file_name} not found in {directory_path}, skipping...\")\n",
    "            continue\n",
    "\n",
    "        plot_file_name = log_file_name.replace('.log', '.png')\n",
    "        plot_path = os.path.join(directory_path, plot_file_name)\n",
    "        \n",
    "        # Extract data from log file\n",
    "        iterations, rewards = parse_log_file(log_file_path)\n",
    "        \n",
    "        if not iterations or not rewards:\n",
    "            print(f\"No valid data found in {log_file_name}, skipping...\")\n",
    "            continue\n",
    "        \n",
    "        # Determine title and subtitle\n",
    "        if 'obs' in log_file_name:\n",
    "            title = \"Obstacle Avoidance Locomotion\"\n",
    "        elif 'rough' in log_file_name:\n",
    "            title = \"General Purpose Locomotion\"\n",
    "        else:\n",
    "            title = log_file_name.replace('.log', '')\n",
    "\n",
    "        mean_reward = sum(rewards) / len(rewards) if rewards else 0\n",
    "        best_reward = max(rewards) if rewards else 0\n",
    "        best_iteration = iterations[rewards.index(best_reward)] if rewards else 0\n",
    "        subtitle = (f\"Mean Reward: \\\\textbf{{{mean_reward:.2f}}} | \"\n",
    "                    f\"Best Reward: \\\\textbf{{{best_reward:.2f}}} (iter: \\\\textbf{{{best_iteration}}})\")\n",
    "        \n",
    "        # Generate the plot\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.grid(True, zorder=0)  # Draw grid behind the plot\n",
    "        plt.plot(iterations, rewards, zorder=1)  # Plot the line above the grid\n",
    "        plt.xlabel('Iterations')\n",
    "        plt.ylabel('Mean Reward')\n",
    "        plt.title(f'{title}\\n{subtitle}', fontsize=16)  # Increase title size only\n",
    "        \n",
    "        if len(iterations) > 1:\n",
    "            plt.xticks(ticks=range(min(iterations), max(iterations)+1, (max(iterations) - min(iterations)) // 13))\n",
    "        \n",
    "        # Save the figure\n",
    "        plt.savefig(plot_path)\n",
    "        plt.close()\n",
    "        print(f\"Figure saved as {plot_path}\")\n",
    "\n",
    "def traverse_directories(parent_directory):\n",
    "    # Use glob to find all subdirectories\n",
    "    subdirectories = [d for d in glob.glob(os.path.join(parent_directory, '*/')) if not os.path.basename(d).startswith('.')]\n",
    "\n",
    "    # Iterate through each subdirectory\n",
    "    for subdir in subdirectories:\n",
    "        # Check if the directory contains the log files\n",
    "        contains_logs = any(os.path.isfile(os.path.join(subdir, log_file)) for log_file in ['obs_train.log', 'rough_train.log'])\n",
    "        \n",
    "        if contains_logs:\n",
    "            process_logs_in_directory(subdir)\n",
    "        else:\n",
    "            print(f\"No relevant log files found in {subdir}, skipping...\")\n",
    "\n",
    "# Example usage:\n",
    "parent_folder = '/home/josep-barbera/Documents/nViNL/experiments/example_experiment_20240823_063325/obstacles'  # Change this to the path of the parent folder\n",
    "traverse_directories(parent_folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe7ea0c-d5c9-482e-aed9-629a371fa8e3",
   "metadata": {},
   "source": [
    "## For the experiments folders directly with more than one run per simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1d5ce929-b30d-4090-aa30-71c6e1d653ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment directory ./my_next_experiments/rough not found, skipping...\n",
      "Experiment directory ./my_next_experiments/obstacles not found, skipping...\n",
      "./02092024_002149_new_baseline/\n",
      "<re.Match object; span=(4, 34), match='Training completed in 01:06:13'>\n",
      "<re.Match object; span=(4, 34), match='Training completed in 01:05:51'>\n",
      "<re.Match object; span=(4, 34), match='Training completed in 01:05:59'>\n",
      "<re.Match object; span=(4, 34), match='Training completed in 01:06:20'>\n",
      "<re.Match object; span=(4, 34), match='Training completed in 01:06:08'>\n",
      "<re.Match object; span=(4, 34), match='Training completed in 00:15:08'>\n",
      "<re.Match object; span=(4, 34), match='Training completed in 00:15:12'>\n",
      "<re.Match object; span=(4, 34), match='Training completed in 00:15:01'>\n",
      "<re.Match object; span=(4, 34), match='Training completed in 00:14:55'>\n",
      "<re.Match object; span=(4, 34), match='Training completed in 00:15:16'>\n",
      "times: [3973, 3951, 3959, 3980, 3968, 908, 912, 901, 895, 916]\n",
      "==================================================\n",
      "None rough\n",
      "3966.2\n",
      "Figure saved as ./02092024_002149_new_baseline/rough_plot.png\n",
      "Results saved to ./02092024_002149_new_baseline/rough_results.txt\n",
      "./02092024_002149_new_baseline/\n",
      "<re.Match object; span=(4, 34), match='Training completed in 01:06:13'>\n",
      "<re.Match object; span=(4, 34), match='Training completed in 01:05:51'>\n",
      "<re.Match object; span=(4, 34), match='Training completed in 01:05:59'>\n",
      "<re.Match object; span=(4, 34), match='Training completed in 01:06:20'>\n",
      "<re.Match object; span=(4, 34), match='Training completed in 01:06:08'>\n",
      "<re.Match object; span=(4, 34), match='Training completed in 00:15:08'>\n",
      "<re.Match object; span=(4, 34), match='Training completed in 00:15:12'>\n",
      "<re.Match object; span=(4, 34), match='Training completed in 00:15:01'>\n",
      "<re.Match object; span=(4, 34), match='Training completed in 00:14:55'>\n",
      "<re.Match object; span=(4, 34), match='Training completed in 00:15:16'>\n",
      "times: [3973, 3951, 3959, 3980, 3968, 908, 912, 901, 895, 916]\n",
      "==================================================\n",
      "None obstacles\n",
      "906.4\n",
      "Figure saved as ./02092024_002149_new_baseline/obstacles_plot.png\n",
      "Results saved to ./02092024_002149_new_baseline/obstacles_results.txt\n",
      "Experiment directory ./already_done/rough not found, skipping...\n",
      "Experiment directory ./already_done/obstacles not found, skipping...\n",
      "Experiment directory ./results/rough not found, skipping...\n",
      "Experiment directory ./results/obstacles not found, skipping...\n",
      "Experiment directory ./weirds/rough not found, skipping...\n",
      "Experiment directory ./weirds/obstacles not found, skipping...\n",
      "./01092024_162133_baseline_well/\n",
      "<re.Match object; span=(4, 34), match='Training completed in 01:08:31'>\n",
      "<re.Match object; span=(4, 34), match='Training completed in 01:19:04'>\n",
      "<re.Match object; span=(4, 34), match='Training completed in 01:09:03'>\n",
      "<re.Match object; span=(4, 34), match='Training completed in 01:08:51'>\n",
      "<re.Match object; span=(4, 34), match='Training completed in 01:08:06'>\n",
      "<re.Match object; span=(4, 34), match='Training completed in 00:15:25'>\n",
      "<re.Match object; span=(4, 34), match='Training completed in 00:15:12'>\n",
      "<re.Match object; span=(4, 34), match='Training completed in 00:15:05'>\n",
      "<re.Match object; span=(4, 34), match='Training completed in 00:14:55'>\n",
      "<re.Match object; span=(4, 34), match='Training completed in 00:14:54'>\n",
      "times: [4111, 4744, 4143, 4131, 4086, 925, 912, 905, 895, 894]\n",
      "==================================================\n",
      "None rough\n",
      "4243.0\n",
      "Figure saved as ./01092024_162133_baseline_well/rough_plot.png\n",
      "Results saved to ./01092024_162133_baseline_well/rough_results.txt\n",
      "./01092024_162133_baseline_well/\n",
      "<re.Match object; span=(4, 34), match='Training completed in 01:08:31'>\n",
      "<re.Match object; span=(4, 34), match='Training completed in 01:19:04'>\n",
      "<re.Match object; span=(4, 34), match='Training completed in 01:09:03'>\n",
      "<re.Match object; span=(4, 34), match='Training completed in 01:08:51'>\n",
      "<re.Match object; span=(4, 34), match='Training completed in 01:08:06'>\n",
      "<re.Match object; span=(4, 34), match='Training completed in 00:15:25'>\n",
      "<re.Match object; span=(4, 34), match='Training completed in 00:15:12'>\n",
      "<re.Match object; span=(4, 34), match='Training completed in 00:15:05'>\n",
      "<re.Match object; span=(4, 34), match='Training completed in 00:14:55'>\n",
      "<re.Match object; span=(4, 34), match='Training completed in 00:14:54'>\n",
      "times: [4111, 4744, 4143, 4131, 4086, 925, 912, 905, 895, 894]\n",
      "==================================================\n",
      "None obstacles\n",
      "906.2\n",
      "Figure saved as ./01092024_162133_baseline_well/obstacles_plot.png\n",
      "Results saved to ./01092024_162133_baseline_well/obstacles_results.txt\n",
      "Experiment directory ./old/rough not found, skipping...\n",
      "Experiment directory ./old/obstacles not found, skipping...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "# LaTeX style setup\n",
    "pgf_with_latex = {\n",
    "    'pgf.texsystem': 'pdflatex',\n",
    "    'text.usetex': True,\n",
    "    'font.size': 10,\n",
    "    'font.family': 'serif',\n",
    "    'font.serif': [],\n",
    "    'font.sans-serif': [],\n",
    "    'font.monospace': [],\n",
    "    'text.latex.preamble': r'\\usepackage[utf8]{inputenc}\\usepackage[T1]{fontenc}\\usepackage[detect-all]{siunitx}\\usepackage{bm}\\usepackage{amsmath}\\usepackage{color}\\usepackage{amsbsy}'\n",
    "}\n",
    "\n",
    "mpl.rcParams.update(pgf_with_latex)\n",
    "plt.rcParams[\"axes.axisbelow\"] = True  # Ensure that the grid is drawn behind everything else\n",
    "\n",
    "\n",
    "\n",
    "def parse_log_file(file_path):\n",
    "    iterations = []\n",
    "    rewards = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            iteration_match = re.search(r'Learning iteration (\\d+)/', line)\n",
    "            if iteration_match:\n",
    "                iteration = int(iteration_match.group(1))\n",
    "            \n",
    "            reward_match = re.search(r'Mean reward: ([\\d\\.-]+)', line)\n",
    "            if reward_match:\n",
    "                reward = float(reward_match.group(1))\n",
    "                iterations.append(iteration)\n",
    "                rewards.append(reward)\n",
    "    return iterations, rewards\n",
    "\n",
    "def parse_experiment_log(file_path):\n",
    "    times = []\n",
    "    best_checkpoint = None\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            time_match = re.search(r'Training completed in (\\d{2}:\\d{2}:\\d{2})', line)\n",
    "            if time_match:\n",
    "                print(time_match)\n",
    "                time_str = time_match.group(1)\n",
    "                # Convert time string (HH:MM:SS) to seconds\n",
    "                h, m, s = map(int, time_str.split(':'))\n",
    "                total_seconds = h * 3600 + m * 60 + s\n",
    "                times.append(total_seconds)\n",
    "            \n",
    "            best_checkpoint_match = re.search(r'Next stage with best rough checkpoint: (\\d+_\\d+\\.\\d+)', line)\n",
    "            if best_checkpoint_match:\n",
    "                best_checkpoint = best_checkpoint_match.group(1)\n",
    "\n",
    "    return times, best_checkpoint\n",
    "\n",
    "def get_studied_parameter_from_folder_name(folder_name):\n",
    "    print(folder_name)\n",
    "    # Adjust the regex to match the parameter name after the timestamp\n",
    "    match = re.search(r'^\\./\\d{8}_\\d{6}_(\\w+)_\\d*\\.?\\d+/?$', folder_name)\n",
    "    if match:\n",
    "        return match.group(1)  # return the parameter name\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def extract_ppo_parameters(file_path):\n",
    "    parameters = []\n",
    "    inside_ppo_section = False\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            if \"##### PPO PARAMETERS ######\" in line:\n",
    "                inside_ppo_section = True\n",
    "            elif \"################################################################################\" in line:\n",
    "                if inside_ppo_section:\n",
    "                    break  # Exit after the PPO section ends\n",
    "            elif inside_ppo_section:\n",
    "                # Adjust regex to capture only lines with parameter name and value\n",
    "                param_match = re.search(r'^\\s*(\\w+):\\s+([\\d\\.\\-e]+)\\s*$', line)\n",
    "                if param_match:\n",
    "                    parameters.append(f\"{param_match.group(1)}: {param_match.group(2)}\")\n",
    "    return parameters\n",
    "\n",
    "def process_run_directories(run_directories, log_file_name):\n",
    "    all_iterations = {}\n",
    "    all_run_rewards = []\n",
    "\n",
    "    for run_dir in run_directories:\n",
    "        log_file_path = os.path.join(run_dir, log_file_name)\n",
    "        if not os.path.isfile(log_file_path):\n",
    "            print(f\"Log file {log_file_path} not found, skipping...\")\n",
    "            continue\n",
    "\n",
    "        iterations, rewards = parse_log_file(log_file_path)\n",
    "        all_run_rewards.append(rewards)\n",
    "\n",
    "        for i, iteration in enumerate(iterations):\n",
    "            if iteration not in all_iterations:\n",
    "                all_iterations[iteration] = []\n",
    "            all_iterations[iteration].append(rewards[i])\n",
    "    \n",
    "    # Sort the iterations\n",
    "    sorted_iterations = sorted(all_iterations.keys())\n",
    "    min_rewards = []\n",
    "    max_rewards = []\n",
    "    mean_rewards = []\n",
    "    all_rewards_per_iteration = []\n",
    "\n",
    "    for iteration in sorted_iterations:\n",
    "        rewards = all_iterations[iteration]\n",
    "        min_rewards.append(min(rewards))\n",
    "        max_rewards.append(max(rewards))\n",
    "        mean_rewards.append(np.mean(rewards))\n",
    "        all_rewards_per_iteration.append(rewards)\n",
    "    \n",
    "    # Determine the best model\n",
    "    best_iteration = sorted_iterations[np.argmax(mean_rewards)]\n",
    "    \n",
    "    return sorted_iterations, all_rewards_per_iteration, min_rewards, max_rewards, mean_rewards, best_iteration\n",
    "\n",
    "def calculate_moving_average(data, window_size):\n",
    "    moving_average = []\n",
    "    for i in range(1, len(data) + 1):\n",
    "        current_window_size = min(i, window_size)  # Gradually increase the window size\n",
    "        window_data = data[i - current_window_size:i]  # Select the data in the current window\n",
    "        window_average = np.mean(window_data)  # Compute the average for this window\n",
    "        moving_average.append(window_average)\n",
    "    return moving_average\n",
    "\n",
    "def save_results_to_txt(iterations, all_rewards_per_iteration, min_rewards, max_rewards, mean_rewards, output_file_path, window_size):\n",
    "    moving_average = calculate_moving_average(mean_rewards, window_size)\n",
    "    \n",
    "    with open(output_file_path, 'w') as f:\n",
    "        # Write the header\n",
    "        header = [\"Iteration\"]\n",
    "        for run_idx in range(len(all_rewards_per_iteration[0])):\n",
    "            header.append(f\"Run_{run_idx+1} Mean Reward\")\n",
    "        header.extend([\"Min Reward\", \"Max Reward\", \"Mean Reward\", \"Moving Average\"])\n",
    "        f.write(\"\\t\".join(header) + \"\\n\")\n",
    "\n",
    "        # Write the data\n",
    "        for i, iteration in enumerate(iterations):\n",
    "            line = [str(iteration)]\n",
    "            line.extend([f\"{reward:.6f}\" for reward in all_rewards_per_iteration[i]])\n",
    "            line.append(f\"{min_rewards[i]:.6f}\")\n",
    "            line.append(f\"{max_rewards[i]:.6f}\")\n",
    "            line.append(f\"{mean_rewards[i]:.6f}\")\n",
    "            if i < len(moving_average):\n",
    "                line.append(f\"{moving_average[i]:.6f}\")\n",
    "            else:\n",
    "                line.append(\"\")  # In case moving_average is shorter\n",
    "            f.write(\"\\t\".join(line) + \"\\n\")\n",
    "\n",
    "    print(f\"Results saved to {output_file_path}\")\n",
    "\n",
    "def plot_results(iterations, min_rewards, max_rewards, mean_rewards, title, plot_path, window_size, mean_time, total_mean, ppo_parameters, studied_parameter, experiment_type):\n",
    "    print(\"=\"*50)\n",
    "    print(studied_parameter, experiment_type)\n",
    "    print(mean_time)\n",
    "\n",
    "    # Baseline values\n",
    "    baseline_total_mean = 11.71 if experiment_type == \"rough\" else 15.39\n",
    "    # baseline_best_reward = 10.21 if experiment_type == \"rough\" else 18.18\n",
    "\n",
    "    # Calculate percentage differences\n",
    "    total_mean_diff = ((total_mean - baseline_total_mean) / baseline_total_mean) * 100\n",
    "    best_index = np.argmax(mean_rewards)\n",
    "    best_iteration = iterations[best_index]\n",
    "    best_reward = mean_rewards[best_index]\n",
    "    # best_reward_diff = ((best_reward - baseline_best_reward) / baseline_best_reward) * 100\n",
    "\n",
    "    # Print information to the terminal\n",
    "    # print(f\"Experiment: {title}\")\n",
    "    # print(f\"Total Mean: {total_mean:.2f} ({total_mean_diff:+.2f}%) compared to baseline {baseline_total_mean}\")\n",
    "    # print(f\"Best Reward: {best_reward:.2f} at iteration {best_iteration} ({best_reward_diff:+.2f}%) compared to baseline {baseline_best_reward}\")\n",
    "    # print(\"=\"*50)\n",
    "\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.grid(True, zorder=0, alpha=0.5)  # Draw grid behind the plot\n",
    "    plt.fill_between(iterations, min_rewards, max_rewards, color='lightblue', alpha=0.7, zorder=1, label='Reward Range')\n",
    "    plt.plot(iterations, mean_rewards, color='tab:blue', zorder=1, label='Episode Reward (mean)')\n",
    "\n",
    "    # Calculate and plot the moving average\n",
    "    if len(mean_rewards) >= window_size:\n",
    "        moving_average = calculate_moving_average(mean_rewards, window_size)\n",
    "        plt.plot(iterations, moving_average, color='black', linewidth=1.5, alpha=0.8, zorder=3, label='Moving Average Ep. Reward')\n",
    "\n",
    "    # Plot a dashed red line for the total mean value with percentage difference\n",
    "    plt.axhline(y=total_mean, color='red', linestyle='--', linewidth=2, alpha=0.5, label=f'Total Mean: {total_mean:.2f})', zorder=4) #({total_mean_diff:+.2f}\\%)', zorder=4)\n",
    "\n",
    "    # Plot a red dot on the best reward point with percentage difference\n",
    "    plt.scatter(best_iteration, best_reward, color='red', s=20, alpha=0.5, zorder=5, label=f'Best Reward: {best_reward:.2f} (It. {best_iteration})')\n",
    "\n",
    "    plt.xlim(0, len(iterations))\n",
    "    if experiment_type == 'rough':\n",
    "        plt.ylim(0, 19)\n",
    "    elif experiment_type == 'obstacles':\n",
    "        plt.ylim(0, 25)\n",
    "    plt.xlabel('Episodes')\n",
    "    plt.ylabel('Mean Reward')\n",
    "    title = title + \" - \" + f\"Mean Training Time: {mean_time/60:.2f} min\"\n",
    "    plt.suptitle(rf'\\textbf{{{title}}}', fontsize=16, fontweight='bold')\n",
    "        \n",
    "    ppo_text = (\n",
    "        (r\"$\\boldsymbol{n_{\\text{\\textbf{epochs}}}}$\" if \"num_learning_epochs\" == studied_parameter else r\"$n_{\\text{epochs}}$\") + r\"= \" + \n",
    "        (r\"$\\boldsymbol{\" + ppo_parameters[3].split(\": \")[1] + r\"}$\" if \"num_learning_epochs\" == studied_parameter else ppo_parameters[3].split(\": \")[1]) + r\" | \" +\n",
    "        \n",
    "        (r\"$\\boldsymbol{n_{\\text{\\textbf{batches}}}}$\" if \"num_mini_batches\" == studied_parameter else r\"$n_{\\text{batches}}$\") + r\"= \" + \n",
    "        (r\"$\\boldsymbol{\" + ppo_parameters[4].split(\": \")[1] + r\"}$\" if \"num_mini_batches\" == studied_parameter else ppo_parameters[4].split(\": \")[1]) + r\" | \" +\n",
    "        \n",
    "        (r\"$\\boldsymbol{\\epsilon}$\" if \"clip_param\" == studied_parameter else r\"$\\epsilon$\") + r\"= \" + \n",
    "        (r\"$\\boldsymbol{\" + ppo_parameters[2].split(\": \")[1] + r\"}$\" if \"clip_param\" == studied_parameter else ppo_parameters[2].split(\": \")[1]) + r\" | \" +\n",
    "        \n",
    "        (r\"$\\boldsymbol{\\gamma}$\" if \"gamma\" == studied_parameter else r\"$\\boldsymbol{\\gamma}$\") + r\"= \" +\n",
    "        (r\"$\\boldsymbol{\" + ppo_parameters[7].split(\": \")[1] + r\"}$\" if \"gamma\" == studied_parameter else r\"$\\boldsymbol{\" + ppo_parameters[7].split(\": \")[1] + r\"}$\") + r\" | \" +\n",
    "        \n",
    "        (r\"$\\boldsymbol{\\lambda}$\" if \"lam\" == studied_parameter else r\"$\\lambda$\") + r\"= \" + \n",
    "        (r\"$\\boldsymbol{\" + ppo_parameters[8].split(\": \")[1] + r\"}$\" if \"lam\" == studied_parameter else ppo_parameters[8].split(\": \")[1]) + r\"\\\\ \" +\n",
    "        \n",
    "        (r\"$\\boldsymbol{c_{\\text{\\text{value}}}}$\" if \"value_loss_coef\" == studied_parameter else r\"$c_{\\text{value}}$\") + r\"= \" +\n",
    "        (r\"$\\boldsymbol{\" + ppo_parameters[5].split(\": \")[1] + r\"}$\" if \"value_loss_coef\" == studied_parameter else ppo_parameters[5].split(\": \")[1]) + r\" | \" +\n",
    "        \n",
    "        (r\"$\\boldsymbol{c_{\\text{\\textbf{entropy}}}}$\" if \"entropy_coef\" == studied_parameter else r\"$\\boldsymbol{c_{\\text{\\textbf{entropy}}}}$\") + r\"= \" +\n",
    "        (r\"$\\boldsymbol{\" + ppo_parameters[6].split(\": \")[1] + r\"}$\" if \"entropy_coef\" == studied_parameter else r\"$\\boldsymbol{\" + ppo_parameters[6].split(\": \")[1]) + r\"}$\" + r\" | \" +\n",
    "        \n",
    "        (r\"$\\boldsymbol{\\alpha}$\" if \"learning_rate\" == studied_parameter else r\"$\\alpha$\") + r\"= \" +\n",
    "        (r\"$\\boldsymbol{\" + ppo_parameters[1].split(\": \")[1] + r\"}$\" if \"learning_rate\" == studied_parameter else ppo_parameters[1].split(\": \")[1]) + r\" | \" +\n",
    "        \n",
    "        (r\"$\\boldsymbol{\\|g\\|_{\\text{\\textbf{max}}}}$\" if \"max_grad_norm\" == studied_parameter else r\"$\\|g\\|_{\\text{max}}$\") + r\"= \" +\n",
    "        (r\"$\\boldsymbol{\" + ppo_parameters[9].split(\": \")[1] + r\"}$\" if \"max_grad_norm\" == studied_parameter else ppo_parameters[9].split(\": \")[1]) + r\" | \" +\n",
    "\n",
    "        (r\"$\\boldsymbol{\\text{\\textbf{KL}}_{\\text{\\textbf{desired}}}}$\" if \"desired_kl\" == studied_parameter else r\"$\\text{KL}_{\\text{desired}}$\") + r\"= \" +\n",
    "        (r\"$\\boldsymbol{\" + ppo_parameters[0].split(\": \")[1] + r\"}$\" if \"desired_kl\" == studied_parameter else ppo_parameters[0].split(\": \")[1]) \n",
    "    )\n",
    "\n",
    "    subtitle = (f\"{ppo_text}\") \n",
    "\n",
    "    # Center the subtitle text\n",
    "    plt.figtext(0.5, 0.92, subtitle, wrap=True, ha='center', fontsize=14)\n",
    "\n",
    "    plt.legend(loc='upper left')\n",
    "    \n",
    "    # Save the figure\n",
    "    plt.savefig(plot_path.replace('.png', '.png'), bbox_inches='tight', transparent=True, format='png', dpi=300)\n",
    "    plt.close()\n",
    "    print(f\"Figure saved as {plot_path.replace('.png', '.png')}\")\n",
    "\n",
    "\n",
    "\n",
    "def process_logs_in_directory(directory_path, experiment_type):\n",
    "    if experiment_type == 'rough':\n",
    "        log_file_name = 'rough_train.log'\n",
    "    elif experiment_type == 'obstacles':\n",
    "        log_file_name = 'obs_train.log'\n",
    "    else:\n",
    "        print(f\"Unknown experiment type: {experiment_type}, skipping...\")\n",
    "        return\n",
    "    \n",
    "    experiment_path = os.path.join(directory_path, experiment_type)\n",
    "    if not os.path.isdir(experiment_path):\n",
    "        print(f\"Experiment directory {experiment_path} not found, skipping...\")\n",
    "        return\n",
    "    \n",
    "    run_directories = glob.glob(os.path.join(experiment_path, 'run_*'))\n",
    "    \n",
    "    if not run_directories:\n",
    "        print(f\"No run directories found in {experiment_path}, skipping...\")\n",
    "        return\n",
    "    \n",
    "    # Extract the studied parameter from the folder name\n",
    "    studied_parameter = get_studied_parameter_from_folder_name(directory_path)\n",
    "\n",
    "    # Extract PPO parameters from the rough_train.log file within the first run_* directory\n",
    "    first_run_dir = run_directories[0]  # Take the first run_* directory\n",
    "    ppo_parameters = extract_ppo_parameters(os.path.join(first_run_dir, log_file_name))\n",
    "\n",
    "    # Process all run directories\n",
    "    iterations, all_rewards_per_iteration, min_rewards, max_rewards, mean_rewards, _ = process_run_directories(run_directories, log_file_name)\n",
    "    \n",
    "    if not iterations:\n",
    "        print(f\"No valid data found in {experiment_path}, skipping...\")\n",
    "        return\n",
    "    \n",
    "    # Extract training times from the experiment.log\n",
    "    experiment_log_file_path = os.path.join(directory_path, 'experiment.log')\n",
    "    if not os.path.isfile(experiment_log_file_path):\n",
    "        print(f\"experiment.log file not found in {directory_path}, skipping...\")\n",
    "        return\n",
    "    \n",
    "    times, _ = parse_experiment_log(experiment_log_file_path)\n",
    "    print(\"times:\", times)\n",
    "    if experiment_type == 'rough':\n",
    "        mean_time = np.mean(times[:5]) if times[:5] else 0\n",
    "    elif experiment_type == 'obstacles':\n",
    "        mean_time = np.mean(times[5:]) if times[5:] else 0\n",
    "\n",
    "    # Calculate total mean of the plotted values\n",
    "    total_mean = np.mean(mean_rewards)\n",
    "\n",
    "    # Determine title, plot path, and txt file path\n",
    "    if experiment_type == 'rough':\n",
    "        title = \"General Purpose Locomotion - Stage 1\"\n",
    "        plot_file_name = \"rough_plot.png\"\n",
    "        txt_file_name = \"rough_results.txt\"\n",
    "    elif experiment_type == 'obstacles':\n",
    "        title = \"Obstacle Avoidance Locomotion - Stage 2\"\n",
    "        plot_file_name = \"obstacles_plot.png\"\n",
    "        txt_file_name = \"obstacles_results.txt\"\n",
    "    \n",
    "    plot_path = os.path.join(directory_path, plot_file_name)\n",
    "    txt_file_path = os.path.join(directory_path, txt_file_name)\n",
    "    \n",
    "    # Generate the plot\n",
    "    window_size = 20  # moving average window size\n",
    "    plot_results(iterations, min_rewards, max_rewards, mean_rewards, title, plot_path, window_size, mean_time, total_mean, ppo_parameters, studied_parameter, experiment_type)\n",
    "    \n",
    "    # Save the results to a .txt file\n",
    "    save_results_to_txt(iterations, all_rewards_per_iteration, min_rewards, max_rewards, mean_rewards, txt_file_path, window_size)\n",
    "\n",
    "\n",
    "def traverse_directories(parent_directory):\n",
    "    # Use glob to find all subdirectories\n",
    "    subdirectories = glob.glob(os.path.join(parent_directory, '*/'))\n",
    "\n",
    "    # Iterate through each subdirectory\n",
    "    for subdir in subdirectories:\n",
    "        # Skip hidden directories (those starting with a dot)\n",
    "        if os.path.basename(subdir).startswith('.'):\n",
    "            print(f\"Skipping hidden directory: {subdir}\")\n",
    "            continue\n",
    "\n",
    "        # Process the logs in the 'rough' subdirectory\n",
    "        process_logs_in_directory(subdir, 'rough')\n",
    "\n",
    "        # Process the logs in the 'obstacles' subdirectory\n",
    "        process_logs_in_directory(subdir, 'obstacles')\n",
    "\n",
    "# Example usage:\n",
    "parent_folder = '.'  # Change this to the path of the parent folder\n",
    "traverse_directories(parent_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "73c48895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files have been copied and renamed successfully to ./results.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import re\n",
    "\n",
    "# Define the current directory and the target directory\n",
    "current_dir = os.getcwd()\n",
    "parent_dir = \".\"\n",
    "results_dir = os.path.join(parent_dir, 'results')\n",
    "\n",
    "# Create the 'results' directory in the parent directory if it doesn't exist\n",
    "if not os.path.exists(results_dir):\n",
    "    os.makedirs(results_dir)\n",
    "\n",
    "# Function to extract the meaningful part of the folder name\n",
    "def extract_name(folder_name):\n",
    "    # Assuming the folder name is structured as date_time_otherstuff\n",
    "    # We want to keep only the \"otherstuff\" part\n",
    "    parts = folder_name.split('_', 2)  # Split only the first two underscores\n",
    "    if len(parts) == 3:\n",
    "        return parts[2]\n",
    "    return folder_name  # If the structure doesn't match, return the original name\n",
    "\n",
    "# Iterate over the folders in the current directory\n",
    "for folder in os.listdir(current_dir):\n",
    "    folder_path = os.path.join(current_dir, folder)\n",
    "    if os.path.isdir(folder_path):  # Check if it's a directory\n",
    "        # Extract the meaningful part of the folder name\n",
    "        clean_name = extract_name(folder)\n",
    "        \n",
    "        # Define paths for the files to be copied\n",
    "        obstacles_file = os.path.join(folder_path, 'obstacles_results.txt')\n",
    "        rough_file = os.path.join(folder_path, 'rough_results.txt')\n",
    "        \n",
    "        # Copy and rename the files if they exist\n",
    "        if os.path.exists(obstacles_file):\n",
    "            new_obstacles_file = os.path.join(results_dir, f\"{clean_name}_obstacles.txt\")\n",
    "            shutil.copy(obstacles_file, new_obstacles_file)\n",
    "        \n",
    "        if os.path.exists(rough_file):\n",
    "            new_rough_file = os.path.join(results_dir, f\"{clean_name}_rough.txt\")\n",
    "            shutil.copy(rough_file, new_rough_file)\n",
    "\n",
    "print(f\"Files have been copied and renamed successfully to {results_dir}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "58538332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current directory: /home/josep-barbera/Documents/nViNL/experiments\n",
      "Checking file: clip_param_0.3_obstacles.txt\n",
      "Found experiment: clip_param_0.3\n",
      "Checking file: clip_param_0.3_rough.txt\n",
      "Found experiment: clip_param_0.3\n",
      "Checking file: clip_param_0.1_rough.txt\n",
      "Found experiment: clip_param_0.1\n",
      "Checking file: baseline_obstacles.txt\n",
      "Checking file: gamma_0.95_entropy_coef_0.005_comparison.png\n",
      "Checking file: gamma_0.95_entropy_coef_0.005_obstacles.txt\n",
      "Found experiment: gamma_0.95_entropy_coef_0.005\n",
      "Checking file: gamma_0.95_entropy_coef_0.005_rough.txt\n",
      "Found experiment: gamma_0.95_entropy_coef_0.005\n",
      "Checking file: clip_param_0.1_obstacles.txt\n",
      "Found experiment: clip_param_0.1\n",
      "Checking file: baseline_rough.txt\n",
      "Checking file: clip_param_0.3_comparison.png\n",
      "Checking file: done\n",
      "Checking file: clip_param_0.1_comparison.png\n",
      "Experiment names found: ['clip_param_0.1', 'clip_param_0.3', 'gamma_0.95_entropy_coef_0.005']\n",
      "Found rough file: clip_param_0.1_rough.txt\n",
      "Found obstacles file: clip_param_0.1_obstacles.txt\n",
      "(['./results/clip_param_0.1_rough.txt'], ['./results/clip_param_0.1_obstacles.txt'])\n",
      "./results/baseline_rough.txt\n",
      "clip_param_0.1\n",
      "==================================================\n",
      "['./results/clip_param_0.1_rough.txt'] ['./results/clip_param_0.1_obstacles.txt'] ./results/baseline_rough.txt ./results/baseline_obstacles.txt clip_param_0.1\n",
      "Figure saved as /home/josep-barbera/Documents/nViNL/experiments/results/clip_param_0.1_comparison.png\n",
      "Found obstacles file: clip_param_0.3_obstacles.txt\n",
      "Found rough file: clip_param_0.3_rough.txt\n",
      "(['./results/clip_param_0.3_rough.txt'], ['./results/clip_param_0.3_obstacles.txt'])\n",
      "./results/baseline_rough.txt\n",
      "clip_param_0.3\n",
      "==================================================\n",
      "['./results/clip_param_0.3_rough.txt'] ['./results/clip_param_0.3_obstacles.txt'] ./results/baseline_rough.txt ./results/baseline_obstacles.txt clip_param_0.3\n",
      "Figure saved as /home/josep-barbera/Documents/nViNL/experiments/results/clip_param_0.3_comparison.png\n",
      "Found obstacles file: gamma_0.95_entropy_coef_0.005_obstacles.txt\n",
      "Found rough file: gamma_0.95_entropy_coef_0.005_rough.txt\n",
      "(['./results/gamma_0.95_entropy_coef_0.005_rough.txt'], ['./results/gamma_0.95_entropy_coef_0.005_obstacles.txt'])\n",
      "./results/baseline_rough.txt\n",
      "gamma_0.95_entropy_coef_0.005\n",
      "==================================================\n",
      "['./results/gamma_0.95_entropy_coef_0.005_rough.txt'] ['./results/gamma_0.95_entropy_coef_0.005_obstacles.txt'] ./results/baseline_rough.txt ./results/baseline_obstacles.txt gamma_0.95_entropy_coef_0.005\n",
      "Figure saved as /home/josep-barbera/Documents/nViNL/experiments/results/gamma_0.95_entropy_coef_0.005_comparison.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import matplotlib as mpl\n",
    "\n",
    "# LaTeX style setup\n",
    "pgf_with_latex = {\n",
    "    'pgf.texsystem': 'pdflatex',\n",
    "    'text.usetex': True,\n",
    "    'font.size': 10,\n",
    "    'font.family': 'serif',\n",
    "    'font.serif': [],\n",
    "    'font.sans-serif': [],\n",
    "    'font.monospace': [],\n",
    "    'text.latex.preamble': r'\\usepackage[utf8]{inputenc}\\usepackage[T1]{fontenc}\\usepackage[detect-all]{siunitx}\\usepackage{bm}\\usepackage{amsmath}\\usepackage{color}\\usepackage{amsbsy}'\n",
    "}\n",
    "\n",
    "mpl.rcParams.update(pgf_with_latex)\n",
    "plt.rcParams[\"axes.axisbelow\"] = True  # Ensure that the grid is drawn behind everything else\n",
    "\n",
    "experiment_name_mapping = {\n",
    "    \"clip_param\": r\"$\\epsilon$\",\n",
    "    \"lam\": r\"$\\lambda$\",\n",
    "    \"gamma\": r\"$\\gamma$\",\n",
    "    \"learning_rate\": r\"$\\alpha$\",\n",
    "    \"max_grad_norm\": r\"$\\|g\\|_{\\text{max}}$\",\n",
    "    \"num_learning_epochs\": r\"$n_{\\text{epochs}}$\",\n",
    "    \"num_mini_batches\": r\"$n_{\\text{batches}}$\",\n",
    "    \"value_loss_coef\": r\"$c_{\\text{value}}$\",\n",
    "    \"entropy_coef\": r\"$c_{\\text{entropy}}$\",\n",
    "    \"desired_kl\": r\"$\\text{KL}_{\\text{desired}}$\"\n",
    "}\n",
    "\n",
    "baseline_values = {\n",
    "    \"clip_param\": \"0.2\",\n",
    "    \"lam\": \"0.95\",\n",
    "    \"gamma\": \"0.99\",\n",
    "    \"learning_rate\": \"1e-3\",\n",
    "    \"max_grad_norm\": \"1.0\",\n",
    "    \"num_learning_epochs\": \"5\",\n",
    "    \"num_mini_batches\": \"4\",\n",
    "    \"value_loss_coef\": \"1.0\",\n",
    "    \"entropy_coef\": \"0.01\",\n",
    "    \"desired_kl\": \"0.01\",\n",
    "    \"seed\": \"1\"\n",
    "}\n",
    "\n",
    "def extract_experiment_names(results_dir):\n",
    "    \"\"\"Extract unique experiment categories from the files in the results directory.\"\"\"\n",
    "    experiment_names = set()\n",
    "    \n",
    "    for file_name in os.listdir(results_dir):\n",
    "        print(f\"Checking file: {file_name}\")  # Debugging line\n",
    "        match = re.match(r'([a-zA-Z_]+\\d*\\.*\\d*)_([a-zA-Z_]+\\d*\\.*\\d*)_(rough|obstacles)\\.txt', file_name)\n",
    "        if match:\n",
    "            experiment_name = f\"{match.group(1)}_{match.group(2)}\"\n",
    "            experiment_names.add(experiment_name)\n",
    "            print(f\"Found experiment: {experiment_name}\")  # Debugging line\n",
    "    \n",
    "    return sorted(experiment_names)\n",
    "\n",
    "def find_experiment_files(results_dir, experiment_name):\n",
    "    \"\"\"Find and return files for a given experiment category.\"\"\"\n",
    "    rough_files = []\n",
    "    obstacles_files = []\n",
    "    \n",
    "    for file_name in os.listdir(results_dir):\n",
    "        if file_name.startswith(experiment_name) and file_name.endswith('_rough.txt'):\n",
    "            rough_files.append(os.path.join(results_dir, file_name))\n",
    "            print(f\"Found rough file: {file_name}\")  # Debugging line\n",
    "        elif file_name.startswith(experiment_name) and file_name.endswith('_obstacles.txt'):\n",
    "            obstacles_files.append(os.path.join(results_dir, file_name))\n",
    "            print(f\"Found obstacles file: {file_name}\")  # Debugging line\n",
    "    \n",
    "    if rough_files and obstacles_files:\n",
    "        return rough_files, obstacles_files\n",
    "    else:\n",
    "        print(f\"Missing files for experiment: {experiment_name}\")  # Debugging line\n",
    "        return None\n",
    "\n",
    "def get_experiment_title(experiment_name):\n",
    "    components = experiment_name.split('_')\n",
    "    title_parts = []\n",
    "    for component in components:\n",
    "        for key in experiment_name_mapping:\n",
    "            if key in component:\n",
    "                title_parts.append(component.replace(key, experiment_name_mapping[key]))\n",
    "                break\n",
    "        else:\n",
    "            title_parts.append(component)\n",
    "    \n",
    "    return \" \".join(title_parts).title()\n",
    "\n",
    "def plot_experiment(files_rough, files_obstacles, baseline_file_rough, baseline_file_obstacles, experiment_name):\n",
    "    print(50*\"=\")\n",
    "    print(files_rough, files_obstacles, baseline_file_rough, baseline_file_obstacles, experiment_name)\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(16, 6), sharey=True)  # Create two subplots side by side\n",
    "\n",
    "    colors = plt.cm.tab10.colors  # Use the tab10 colormap, which provides 10 distinct colors\n",
    "    value_to_color = {}  # Dictionary to map hyperparameter values to colors\n",
    "\n",
    "    # Plotting for rough\n",
    "    axs[0].set_title('Rough')\n",
    "    plot_single_experiment(axs[0], files_rough, baseline_file_rough, experiment_name, colors, value_to_color)\n",
    "\n",
    "    # Plotting for obstacles\n",
    "    axs[1].set_title('Obstacles')\n",
    "    plot_single_experiment(axs[1], files_obstacles, baseline_file_obstacles, experiment_name, colors, value_to_color)\n",
    "    \n",
    "    title = get_experiment_title(experiment_name)\n",
    "    fig.suptitle(f'Baseline vs. New Params', fontsize=16)\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.95])  # Adjust layout to include suptitle\n",
    "    \n",
    "    output_dir = '/home/josep-barbera/Documents/nViNL/experiments/results'  # Adjust this path as needed\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    output_path = os.path.join(output_dir, f'{experiment_name}_comparison.png')\n",
    "    plt.savefig(output_path, dpi=200, transparent=True)\n",
    "    plt.close(fig)  # Close the figure to free up memory\n",
    "    print(f\"Figure saved as {output_path}\")  # Debugging line\n",
    "\n",
    "def plot_single_experiment(ax, files, baseline_file, experiment_name, colors, value_to_color):\n",
    "    \"\"\"Helper function to plot a single experiment on a given axis.\"\"\"\n",
    "    \n",
    "    # Extract parameter names and values from experiment_name\n",
    "    match = re.match(r'([a-zA-Z_]+)(\\d*\\.*\\d*)_([a-zA-Z_]+)(\\d*\\.*\\d*)', experiment_name)\n",
    "    if match:\n",
    "        param1, value1, param2, value2 = match.groups()\n",
    "        \n",
    "        # Clean up the parameter names (remove any trailing underscores)\n",
    "        param1 = param1.rstrip('_')\n",
    "        param2 = param2.rstrip('_')\n",
    "        \n",
    "        # Retrieve LaTeX symbols for both parameters\n",
    "        param1_label = experiment_name_mapping.get(param1, param1)\n",
    "        param2_label = experiment_name_mapping.get(param2, param2)\n",
    "        \n",
    "        # Get the correct baseline values for both parameters\n",
    "        baseline_value1 = baseline_values.get(param1, \"N/A\")\n",
    "        baseline_value2 = baseline_values.get(param2, \"N/A\")\n",
    "        \n",
    "        # Format the baseline label to include both parameters\n",
    "        baseline_label = f\"baseline: {param1_label} = {baseline_value1}, {param2_label} = {baseline_value2}\"\n",
    "\n",
    "        # Plot baseline first\n",
    "        data = pd.read_csv(baseline_file, sep='\\t')\n",
    "        moving_average = data['Moving Average']\n",
    "        min_reward = data['Min Reward']\n",
    "        max_reward = data['Max Reward']\n",
    "\n",
    "        ax.fill_between(data.index, min_reward, max_reward, color='gray', alpha=0.3)\n",
    "        ax.plot(data.index, moving_average, color='gray', label=baseline_label, linestyle='--')\n",
    "\n",
    "        # Extract the values and ensure consistent order\n",
    "        file_paths_sorted = sorted(files, key=lambda x: os.path.basename(x).split('_')[-2])\n",
    "        labels_and_colors = {}\n",
    "\n",
    "        # Assign colors consistently\n",
    "        for i, file_path in enumerate(file_paths_sorted):\n",
    "            data = pd.read_csv(file_path, sep='\\t')\n",
    "            moving_average = data['Moving Average']\n",
    "            min_reward = data['Min Reward']\n",
    "            max_reward = data['Max Reward']\n",
    "\n",
    "            # Generate label with both parameters and their values\n",
    "            label = f\"New params: {param1_label} = {value1}, {param2_label} = {value2}\"\n",
    "\n",
    "            # Ensure consistent color assignment\n",
    "            color = colors[i % len(colors)]\n",
    "\n",
    "            labels_and_colors[label] = color\n",
    "\n",
    "            ax.fill_between(data.index, min_reward, max_reward, color=color, alpha=0.3)\n",
    "            ax.plot(data.index, moving_average, color=color, label=label)\n",
    "\n",
    "        # Retrieve and sort the legend handles by our custom ordering\n",
    "        handles, labels = ax.get_legend_handles_labels()\n",
    "        sorted_labels_and_handles = sorted(\n",
    "            zip(labels, handles),\n",
    "            key=lambda t: (0 if \"baseline\" in t[0] else (1 if labels_and_colors[t[0]] == colors[0] else 2))\n",
    "        )\n",
    "        sorted_labels, sorted_handles = zip(*sorted_labels_and_handles)\n",
    "\n",
    "        ax.legend(sorted_handles, sorted_labels, loc='upper left')\n",
    "        ax.set_xlim(0, len(data.index))\n",
    "        ax.set_xlabel('Episodes')\n",
    "        ax.set_ylabel('Mean Reward')\n",
    "        ax.grid(True, zorder=0, alpha=0.5)\n",
    "\n",
    "    else:\n",
    "        print(f\"Could not match the experiment name pattern: {experiment_name}\")\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    print(\"Current directory:\", os.getcwd())\n",
    "    results_dir = './results'\n",
    "    \n",
    "    experiment_names = extract_experiment_names(results_dir)\n",
    "    print(\"Experiment names found:\", experiment_names)\n",
    "\n",
    "    for experiment in experiment_names:\n",
    "        result = find_experiment_files(results_dir, experiment)\n",
    "        print(result)\n",
    "        \n",
    "        if result:\n",
    "            rough_files, obstacles_files = result\n",
    "            baseline_rough = os.path.join(results_dir, 'baseline_rough.txt')\n",
    "            print(baseline_rough)\n",
    "            baseline_obstacles = os.path.join(results_dir, 'baseline_obstacles.txt')\n",
    "            print(experiment)\n",
    "            plot_experiment(rough_files, obstacles_files, baseline_rough, baseline_obstacles, experiment)\n",
    "        else:\n",
    "            print(f\"Skipping experiment {experiment} - incomplete data (missing required files).\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663dc141",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "c255fce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Figure saved as ./old/example_experiment_20240823_063325/rough_plot.png\n",
      "Figure saved as ./old/example_experiment_20240823_063325/obstacles_plot.png\n",
      "Figure saved as ./old/example_experiment_20240822_215620/rough_plot.png\n",
      "Figure saved as ./old/example_experiment_20240822_215620/obstacles_plot.png\n",
      "Experiment directory ./old/example_experiment_20240630_104019/rough not found, skipping...\n",
      "Experiment directory ./old/example_experiment_20240630_104019/obstacles not found, skipping...\n",
      "Experiment directory ./old/example_experiment_20240629_163213/rough not found, skipping...\n",
      "Experiment directory ./old/example_experiment_20240629_163213/obstacles not found, skipping...\n",
      "Experiment directory ./old/example_experiment_20240821_151510/rough not found, skipping...\n",
      "Experiment directory ./old/example_experiment_20240821_151510/obstacles not found, skipping...\n",
      "Experiment directory ./old/example_experiment_20240821_214515/rough not found, skipping...\n",
      "Experiment directory ./old/example_experiment_20240821_214515/obstacles not found, skipping...\n",
      "Experiment directory ./old/example_experiment_20240630_145416/rough not found, skipping...\n",
      "Experiment directory ./old/example_experiment_20240630_145416/obstacles not found, skipping...\n",
      "Experiment directory ./old/example_experiment_20240629_183303/rough not found, skipping...\n",
      "Experiment directory ./old/example_experiment_20240629_183303/obstacles not found, skipping...\n",
      "Experiment directory ./old/example_experiment_20240630_072746/rough not found, skipping...\n",
      "Experiment directory ./old/example_experiment_20240630_072746/obstacles not found, skipping...\n",
      "Figure saved as ./old/30082024_133653_baseline/rough_plot.png\n",
      "Figure saved as ./old/30082024_133653_baseline/obstacles_plot.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "# LaTeX style setup\n",
    "pgf_with_latex = {\n",
    "    'pgf.texsystem': 'pdflatex',\n",
    "    'text.usetex': True,\n",
    "    'font.size': 10,\n",
    "    'font.family': 'serif',\n",
    "    'font.serif': [],\n",
    "    'font.sans-serif': [],\n",
    "    'font.monospace': [],\n",
    "    'text.latex.preamble': r'\\usepackage[utf8]{inputenc}\\usepackage[T1]{fontenc}\\usepackage[detect-all]{siunitx}\\usepackage{bm}\\usepackage{amsmath}\\usepackage{color}\\usepackage{amsbsy}'\n",
    "}\n",
    "\n",
    "mpl.rcParams.update(pgf_with_latex)\n",
    "plt.rcParams[\"axes.axisbelow\"] = True  # Ensure that the grid is drawn behind everything else\n",
    "\n",
    "def parse_log_file(file_path):\n",
    "    iterations = []\n",
    "    rewards = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            iteration_match = re.search(r'Learning iteration (\\d+)/', line)\n",
    "            if iteration_match:\n",
    "                iteration = int(iteration_match.group(1))\n",
    "            \n",
    "            reward_match = re.search(r'Mean reward: ([\\d\\.-]+)', line)\n",
    "            if reward_match:\n",
    "                reward = float(reward_match.group(1))\n",
    "                iterations.append(iteration)\n",
    "                rewards.append(reward)\n",
    "    return iterations, rewards\n",
    "\n",
    "def get_studied_parameter_from_folder_name(folder_name):\n",
    "    match = re.search(r'^\\./\\d{8}_\\d{6}_(\\w+)_\\d*\\.?\\d+/?$', folder_name)\n",
    "    if match:\n",
    "        return match.group(1)  # return the parameter name\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def extract_ppo_parameters(file_path):\n",
    "    parameters = []\n",
    "    inside_ppo_section = False\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            if \"##### PPO PARAMETERS ######\" in line:\n",
    "                inside_ppo_section = True\n",
    "            elif \"################################################################################\" in line:\n",
    "                if inside_ppo_section:\n",
    "                    break  # Exit after the PPO section ends\n",
    "            elif inside_ppo_section:\n",
    "                param_match = re.search(r'^\\s*(\\w+):\\s+([\\d\\.\\-e]+)\\s*$', line)\n",
    "                if param_match:\n",
    "                    parameters.append(f\"{param_match.group(1)}: {param_match.group(2)}\")\n",
    "    return parameters\n",
    "\n",
    "def process_run_directories(run_directories, log_file_name):\n",
    "    all_iterations = {}\n",
    "    all_run_rewards = []\n",
    "\n",
    "    for run_dir in run_directories:\n",
    "        log_file_path = os.path.join(run_dir, log_file_name)\n",
    "        if not os.path.isfile(log_file_path):\n",
    "            print(f\"Log file {log_file_path} not found, skipping...\")\n",
    "            continue\n",
    "\n",
    "        iterations, rewards = parse_log_file(log_file_path)\n",
    "        all_run_rewards.append(rewards)\n",
    "\n",
    "        for i, iteration in enumerate(iterations):\n",
    "            if iteration not in all_iterations:\n",
    "                all_iterations[iteration] = []\n",
    "            all_iterations[iteration].append(rewards[i])\n",
    "    \n",
    "    # Sort the iterations\n",
    "    sorted_iterations = sorted(all_iterations.keys())\n",
    "    min_rewards = []\n",
    "    max_rewards = []\n",
    "    mean_rewards = []\n",
    "    all_rewards_per_iteration = []\n",
    "\n",
    "    for iteration in sorted_iterations:\n",
    "        rewards = all_iterations[iteration]\n",
    "        min_rewards.append(min(rewards))\n",
    "        max_rewards.append(max(rewards))\n",
    "        mean_rewards.append(np.mean(rewards))\n",
    "        all_rewards_per_iteration.append(rewards)\n",
    "    \n",
    "    # Determine the best model\n",
    "    best_iteration = sorted_iterations[np.argmax(mean_rewards)]\n",
    "    \n",
    "    return sorted_iterations, all_rewards_per_iteration, min_rewards, max_rewards, mean_rewards, best_iteration\n",
    "\n",
    "def calculate_moving_average(data, window_size):\n",
    "    moving_average = []\n",
    "    for i in range(1, len(data) + 1):\n",
    "        current_window_size = min(i, window_size)  # Gradually increase the window size\n",
    "        window_data = data[i - current_window_size:i]  # Select the data in the current window\n",
    "        window_average = np.mean(window_data)  # Compute the average for this window\n",
    "        moving_average.append(window_average)\n",
    "    return moving_average\n",
    "\n",
    "def save_results_to_txt(iterations, all_rewards_per_iteration, min_rewards, max_rewards, mean_rewards, output_file_path, window_size):\n",
    "    moving_average = calculate_moving_average(mean_rewards, window_size)\n",
    "    \n",
    "    with open(output_file_path, 'w') as f:\n",
    "        header = [\"Iteration\"]\n",
    "        for run_idx in range(len(all_rewards_per_iteration[0])):\n",
    "            header.append(f\"Run_{run_idx+1} Mean Reward\")\n",
    "        header.extend([\"Min Reward\", \"Max Reward\", \"Mean Reward\", \"Moving Average\"])\n",
    "        f.write(\"\\t\".join(header) + \"\\n\")\n",
    "\n",
    "        for i, iteration in enumerate(iterations):\n",
    "            line = [str(iteration)]\n",
    "            line.extend([f\"{reward:.6f}\" for reward in all_rewards_per_iteration[i]])\n",
    "            line.append(f\"{min_rewards[i]:.6f}\")\n",
    "            line.append(f\"{max_rewards[i]:.6f}\")\n",
    "            line.append(f\"{mean_rewards[i]:.6f}\")\n",
    "            if i < len(moving_average):\n",
    "                line.append(f\"{moving_average[i]:.6f}\")\n",
    "            else:\n",
    "                line.append(\"\")  # In case moving_average is shorter\n",
    "            f.write(\"\\t\".join(line) + \"\\n\")\n",
    "\n",
    "    print(f\"Results saved to {output_file_path}\")\n",
    "\n",
    "def plot_results(iterations, min_rewards, max_rewards, mean_rewards, title, plot_path, window_size, mean_time, total_mean, ppo_parameters, studied_parameter, experiment_type):\n",
    "    if studied_parameter == 'desired_kl' and ppo_parameters[0].split(\": \")[1] == \"0.005\" and experiment_type == \"obstacles\":\n",
    "        print(\"hellllooooo\")\n",
    "        iterations = [x - 1000 for x in iterations]\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.grid(True, zorder=0, alpha=0.5)  # Draw grid behind the plot\n",
    "    # plt.fill_between(iterations, min_rewards, max_rewards, color='lightblue', alpha=0.7, zorder=1, label='Reward Range')\n",
    "    plt.plot(iterations, mean_rewards, color='tab:blue', zorder=1, label='Episode Reward (mean)')\n",
    "\n",
    "    if len(mean_rewards) >= window_size:\n",
    "        moving_average = calculate_moving_average(mean_rewards, window_size)\n",
    "        plt.plot(iterations, moving_average, color='black', linewidth=1.5, alpha=0.8, zorder=3, label='Moving Average Ep. Reward')\n",
    "\n",
    "    best_index = np.argmax(mean_rewards)\n",
    "    best_iteration = iterations[best_index]\n",
    "    best_reward = mean_rewards[best_index]\n",
    "\n",
    "    plt.axhline(y=total_mean, color='red', linestyle='--', linewidth=2, alpha=0.5, label=f'Total Mean: {total_mean:.2f}', zorder=4)\n",
    "\n",
    "    plt.scatter(best_iteration, best_reward, color='red', s=20, alpha=0.5, zorder=5, label=f'Best Reward: {best_reward:.2f} (It. {best_iteration})')\n",
    "    \n",
    "    plt.xlim(0, len(iterations))\n",
    "    if experiment_type == 'rough':\n",
    "        plt.ylim(0, 17)\n",
    "    elif experiment_type == 'obstacles':\n",
    "        plt.ylim(0, 21)\n",
    "\n",
    "    plt.xlabel('Episodes')\n",
    "    plt.ylabel('Mean Reward')\n",
    "    # title = title + \" - \" + f\"Mean Training Time: {mean_time/60:.2f} min\"\n",
    "    plt.title(rf'\\textbf{{{title}}}', fontsize=16, fontweight='bold')\n",
    "        \n",
    "    # ppo_text = (\n",
    "    #     (r\"$\\boldsymbol{n_{\\text{\\textbf{epochs}}}}$\" if \"num_learning_epochs\" == studied_parameter else r\"$n_{\\text{epochs}}$\") + r\"= \" + \n",
    "    #     (r\"$\\boldsymbol{\" + ppo_parameters[3].split(\": \")[1] + r\"}$\" if \"num_learning_epochs\" == studied_parameter else ppo_parameters[3].split(\": \")[1]) + r\" | \" +\n",
    "        \n",
    "    #     (r\"$\\boldsymbol{n_{\\text{\\textbf{batches}}}}$\" if \"num_mini_batches\" == studied_parameter else r\"$n_{\\text{batches}}$\") + r\"= \" + \n",
    "    #     (r\"$\\boldsymbol{\" + ppo_parameters[4].split(\": \")[1] + r\"}$\" if \"num_mini_batches\" == studied_parameter else ppo_parameters[4].split(\": \")[1]) + r\" | \" +\n",
    "        \n",
    "    #     (r\"$\\boldsymbol{\\epsilon}$\" if \"clip_param\" == studied_parameter else r\"$\\epsilon$\") + r\"= \" + \n",
    "    #     (r\"$\\boldsymbol{\" + ppo_parameters[2].split(\": \")[1] + r\"}$\" if \"clip_param\" == studied_parameter else ppo_parameters[2].split(\": \")[1]) + r\" | \" +\n",
    "        \n",
    "    #     (r\"$\\boldsymbol{\\gamma}$\" if \"gamma\" == studied_parameter else r\"$\\gamma$\") + r\"= \" +\n",
    "    #     (r\"$\\boldsymbol{\" + ppo_parameters[7].split(\": \")[1] + r\"}$\" if \"gamma\" == studied_parameter else ppo_parameters[7].split(\": \")[1]) + r\" | \" +\n",
    "        \n",
    "    #     (r\"$\\boldsymbol{\\lambda}$\" if \"lam\" == studied_parameter else r\"$\\lambda$\") + r\"= \" + \n",
    "    #     (r\"$\\boldsymbol{\" + ppo_parameters[8].split(\": \")[1] + r\"}$\" if \"lam\" == studied_parameter else ppo_parameters[8].split(\": \")[1]) + r\"\\\\ \" +\n",
    "        \n",
    "    #     (r\"$\\boldsymbol{c_{\\text{\\text{value}}}}$\" if \"value_loss_coef\" == studied_parameter else r\"$c_{\\text{value}}$\") + r\"= \" +\n",
    "    #     (r\"$\\boldsymbol{\" + ppo_parameters[5].split(\": \")[1] + r\"}$\" if \"value_loss_coef\" == studied_parameter else ppo_parameters[5].split(\": \")[1]) + r\" | \" +\n",
    "        \n",
    "    #     (r\"$\\boldsymbol{c_{\\text{\\textbf{entropy}}}}$\" if \"entropy_coef\" == studied_parameter else r\"$c_{\\text{entropy}}$\") + r\"= \" +\n",
    "    #     (r\"$\\boldsymbol{\" + ppo_parameters[6].split(\": \")[1] + r\"}$\" if \"entropy_coef\" == studied_parameter else ppo_parameters[6].split(\": \")[1]) + r\" | \" +\n",
    "        \n",
    "    #     (r\"$\\boldsymbol{\\alpha}$\" if \"learning_rate\" == studied_parameter else r\"$\\alpha$\") + r\"= \" +\n",
    "    #     (r\"$\\boldsymbol{\" + ppo_parameters[1].split(\": \")[1] + r\"}$\" if \"learning_rate\" == studied_parameter else ppo_parameters[1].split(\": \")[1]) + r\" | \" +\n",
    "        \n",
    "    #     (r\"$\\boldsymbol{\\|g\\|_{\\text{\\textbf{max}}}}$\" if \"max_grad_norm\" == studied_parameter else r\"$\\|g\\|_{\\text{max}}$\") + r\"= \" +\n",
    "    #     (r\"$\\boldsymbol{\" + ppo_parameters[9].split(\": \")[1] + r\"}$\" if \"max_grad_norm\" == studied_parameter else ppo_parameters[9].split(\": \")[1]) + r\" | \" +\n",
    "\n",
    "    #     (r\"$\\boldsymbol{\\text{\\textbf{KL}}_{\\text{\\textbf{desired}}}}$\" if \"desired_kl\" == studied_parameter else r\"$\\text{KL}_{\\text{desired}}$\") + r\"= \" +\n",
    "    #     (r\"$\\boldsymbol{\" + ppo_parameters[0].split(\": \")[1] + r\"}$\" if \"desired_kl\" == studied_parameter else ppo_parameters[0].split(\": \")[1]) \n",
    "    # )\n",
    "\n",
    "    # subtitle = (f\"{ppo_text}\")\n",
    "\n",
    "    # plt.figtext(0.5, 0.92, subtitle, wrap=True, ha='center', fontsize=14)\n",
    "\n",
    "    plt.legend(loc='lower left')\n",
    "\n",
    "    plt.savefig(plot_path.replace('.png', '.png'), bbox_inches='tight', transparent = True, format='png', dpi=300)\n",
    "    plt.close()\n",
    "    print(f\"Figure saved as {plot_path.replace('.png', '.png')}\")\n",
    "\n",
    "def process_logs_in_directory(directory_path, experiment_type):\n",
    "    if experiment_type == 'rough':\n",
    "        log_file_name = 'rough_train.log'\n",
    "    elif experiment_type == 'obstacles':\n",
    "        log_file_name = 'obs_train.log'\n",
    "    else:\n",
    "        print(f\"Unknown experiment type: {experiment_type}, skipping...\")\n",
    "        return\n",
    "    \n",
    "    experiment_path = os.path.join(directory_path, experiment_type)\n",
    "    if not os.path.isdir(experiment_path):\n",
    "        print(f\"Experiment directory {experiment_path} not found, skipping...\")\n",
    "        return\n",
    "    \n",
    "    run_directories = glob.glob(os.path.join(experiment_path, 'run_*'))\n",
    "    \n",
    "    if not run_directories:\n",
    "        print(f\"No run directories found in {experiment_path}, skipping...\")\n",
    "        return\n",
    "    \n",
    "    studied_parameter = get_studied_parameter_from_folder_name(directory_path)\n",
    "\n",
    "    first_run_dir = run_directories[0]\n",
    "    ppo_parameters = extract_ppo_parameters(os.path.join(first_run_dir, log_file_name))\n",
    "\n",
    "    iterations, all_rewards_per_iteration, min_rewards, max_rewards, mean_rewards, _ = process_run_directories(run_directories, log_file_name)\n",
    "    \n",
    "    if not iterations:\n",
    "        print(f\"No valid data found in {experiment_path}, skipping...\")\n",
    "        return\n",
    "    \n",
    "    experiment_log_file_path = os.path.join(directory_path, 'experiment.log')\n",
    "    mean_time = 0  # Default value for mean time\n",
    "\n",
    "    if os.path.isfile(experiment_log_file_path):\n",
    "        times, _ = parse_experiment_log(experiment_log_file_path)\n",
    "        mean_time = np.mean(times) if times else 0\n",
    "\n",
    "    total_mean = np.mean(mean_rewards)\n",
    "\n",
    "    if experiment_type == 'rough':\n",
    "        title = \"General Purpose Locomotion - Stage 1\"\n",
    "        plot_file_name = \"rough_plot.png\"\n",
    "        txt_file_name = \"rough_results.txt\"\n",
    "    elif experiment_type == 'obstacles':\n",
    "        title = \"Obstacle Avoidance Locomotion - Stage 2\"\n",
    "        plot_file_name = \"obstacles_plot.png\"\n",
    "        txt_file_name = \"obstacles_results.txt\"\n",
    "    \n",
    "    plot_path = os.path.join(directory_path, plot_file_name)\n",
    "    txt_file_path = os.path.join(directory_path, txt_file_name)\n",
    "    \n",
    "    window_size = 20  # moving average window size\n",
    "    plot_results(iterations, min_rewards, max_rewards, mean_rewards, title, plot_path, window_size, mean_time, total_mean, ppo_parameters, studied_parameter, experiment_type)\n",
    "    \n",
    "def traverse_directories(parent_directory):\n",
    "    subdirectories = glob.glob(os.path.join(parent_directory, '*/'))\n",
    "\n",
    "    for subdir in subdirectories:\n",
    "        if os.path.basename(subdir).startswith('.'):\n",
    "            print(f\"Skipping hidden directory: {subdir}\")\n",
    "            continue\n",
    "\n",
    "        process_logs_in_directory(subdir, 'rough')\n",
    "        process_logs_in_directory(subdir, 'obstacles')\n",
    "\n",
    "# Example usage:\n",
    "parent_folder = './old/'  # Change this to the path of the parent folder\n",
    "traverse_directories(parent_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d0aec5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
